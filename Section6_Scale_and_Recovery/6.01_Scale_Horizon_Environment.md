# 6.1 Scale Horizon Environment

## Exam Objective

> **4.6.1. Scale Horizon environment.**
> - Analyze and evaluate to scale your Horizon Infrastructure (CS, App Volumes, DEM)

---

## 水平スケーリング vs 垂直スケーリング

スケーリング方針を決定するための判断基準：

| 判断基準 | 水平スケーリング (Scale-Out) | 垂直スケーリング (Scale-Up) |
|---|---|---|
| **アプローチ** | コンポーネント数を増加 | 既存コンポーネントのリソースを増加 |
| **可用性への影響** | N+1 冗長性を確保可能 | 単一障害点 (SPOF) のリスクが残る |
| **適用判断** | セッション数・ユーザー数が上限に到達 | CPU/メモリ使用率がボトルネック |
| **適用コンポーネント** | Connection Server, UAG, App Volumes Manager | vCenter Server, DB Server, File Server |
| **コスト特性** | ライセンス・ハードウェアコストが線形増加 | 単価が高くなりがちだが管理は容易 |

### 判断フロー

1. **ボトルネック分析**: CPU使用率 > 80%持続、メモリ使用率 > 90%持続、応答時間劣化
2. **上限値チェック**: Configuration Maximums に対する現在の使用率を確認
3. **垂直スケーリングの余地**: vCPU/メモリの追加で解消可能か
4. **水平スケーリングの必要性**: 上限値に到達、または冗長性要件がある場合

---

## Connection Server のスケーリング

### Configuration Maximums

| パラメータ | 上限値 |
|---|---|
| 1 CS あたりの最大セッション数 | **4,000**（トンネリング無効時） |
| 1 CS あたりの最大セッション数（トンネリング有効時） | **2,000** |
| Pod あたりの最大 Connection Server 数 | **7** |
| Pod あたりの最大セッション数 | **20,000** |
| CPA フェデレーション最大セッション数 | **250,000** |
| CPA フェデレーション最大 Pod 数 | **50** |
| CPA フェデレーション最大 Site 数 | **15** |
| CPA フェデレーション CS インスタンス合計 | **350** |

> **重要**: Blast Secure Gateway / PCoIP Secure Gateway / HTTP(S) Secure Tunnel を Connection Server 上で有効にすると、セッション上限は 4,000 → 2,000 に低下する。

### クォーラム要件（Horizon 2309 以降）

Pod 内で少なくとも **(N/2)+1** 個のノードが実行中である必要がある（N = Pod に登録されたノード合計数）。実行中のノード数がこの閾値を下回ると、プロビジョニングおよびイメージング操作は実行されない。

```
例: Pod に 5 台の CS が登録 → 最低 (5/2)+1 = 3.5 → 4 台が稼働している必要あり
```

### サイジング計算

```
必要 CS 数 = ceil(目標セッション数 / CS あたりセッション上限) + 1 (N+1 冗長)

例: 8,000 セッション（トンネリング無効）
  = ceil(8,000 / 4,000) + 1 = 3 台
```

### スケーリング手法

**水平スケーリング（推奨）**:
- Replica Server として追加インストール → 自動的に LDAP レプリケーショングループに参加
- ロードバランサーにプールメンバーとして追加（Session Persistence / Sticky Connection 必須）
- ヘルスチェック設定: `/broker/xml` エンドポイントを監視
- UAG (Unified Access Gateway) を組み合わせる場合、各 UAG は 1 つの Pod に関連付ける

**垂直スケーリング**:
- Omnissa 推奨: 4 vCPU / 10 GB RAM（標準）、vCPU・メモリ増強で処理能力向上
- ログインストーム時のピーク負荷を考慮したサイジング

### ボトルネック分析の指標

| 指標 | 正常範囲 | 要対応 |
|---|---|---|
| CPU 使用率 | < 60% | > 80% 持続 |
| メモリ使用率 | < 70% | > 90% 持続 |
| LDAP レプリケーション遅延 | < 5 秒 | > 30 秒 |
| ログイン応答時間 | < 3 秒 | > 10 秒 |
| Event DB クエリ時間 | < 1 秒 | > 5 秒 |

### Pod and Block アーキテクチャ

リソース容量の拡張は Block 単位で行う：

- **Block**: 1つ以上のリソースクラスタで構成。通常、専用の Hypervisor Manager（vCenter）を持つ
- **Pod**: 最大 7 CS + 複数 Block で構成。最大 20,000 セッション
- Block の追加 → Pod 内のリソース容量拡大
- Pod の追加 → CPA でフェデレーションし、20,000 セッション超に対応

> **設計上の考慮**: vCenter を単一にすると SPOF かつ性能ボトルネックになり得る。障害ドメインの影響範囲を考慮し、複数の vCenter（複数 Block）に分散することを推奨。

---

## App Volumes のスケーリング

### Configuration Maximums

| パラメータ | 推奨値 |
|---|---|
| App Volumes Manager あたりのユーザー数 | **~2,000**（環境依存） |
| 本番環境の最小 Manager 数 | **2**（ロードバランサー配下） |
| Manager あたりの vCenter 登録数 | 複数 vCenter 対応 |

> **参照**: KB 67354「App Volumes Sizing Limits and Recommendations」でテスト済みの上限値を確認すること。

### スケーリング手法

**水平スケーリング（Multi-Manager）**:
1. 追加の App Volumes Manager をインストール
2. 同一 SQL データベースに接続（サイト内で同一 DB を共有）
3. ロードバランサー配下に配置
   - Health Monitor: `GET /health_check` (HTTPS, Port 443)
   - Persistence: Source IP
   - Algorithm: Least Connections

**垂直スケーリング**:
- Manager VM の vCPU / メモリ増強
- ログインストーム対応（同時アタッチ操作が集中）

### ストレージ容量計算

```
必要ストレージ = (Package 数 × 平均サイズ)
               + (Writable Volume 数 × 平均サイズ)
               + Storage Group レプリカ分
               + オーバーヘッド (20%)
```

### ボトルネック分析

| 指標 | 確認方法 |
|---|---|
| ログインストームによる遅延 | Package attach 所要時間の監視 |
| DB パフォーマンス | SQL Server のクエリ実行時間 |
| ストレージ I/O | データストアの IOPS / レイテンシ |
| Manager CPU / メモリ | VM レベルのリソース監視 |

### Multi-Site 設計

- サイトごとに App Volumes Manager インスタンスを配置し、**サイトごとに個別の SQL データベース**を使用（推奨）
- Package のレプリケーション: Storage Group 機能で自動複製、または vSphere Storage Replication / 手動コピー
- Writable Volume はサイト間でのレプリケーションが必要（ユーザー移動時）
- フェイルオーバー時にユーザーが別サイトの Package にアクセスするには、ユーザー Entitlement のレプリケーションも必要（Multi-Instance 管理）
- Storage Group のデータは DB 内の静的構成情報として格納（通常 5 MB 以下）

---

## DEM のスケーリング

### アーキテクチャ特性

DEM は専用サーバーやデータベースに依存しない軽量アーキテクチャ：
- **Configuration Share**: SMB ファイル共有（IT 設定データ、読み取り専用）
- **Profile Archive Share**: SMB ファイル共有（ユーザー設定データ、読み書き）
- **FlexEngine**: デスクトップ / RDSH 上のエージェント

> **スケーラビリティ**: 単一 Windows ファイルサーバーで **10,000 ユーザー**をサポート可能。100,000 デバイス以上の環境でもスケール限界に達しない実績あり。

### Configuration Maximums / サイジング

| パラメータ | 推奨値 |
|---|---|
| ファイルサーバーあたりのユーザー数 | **~10,000** |
| ファイルサーバー推奨スペック（10,000ユーザー） | 4 vCPU / 16 GB RAM |
| Configuration Share 容量 | **~1 GB / 5,000 ユーザー** |
| Profile Archive Share 容量 | **~100 MB / ユーザー** |

### スケーリング手法

**水平スケーリング（推奨）**:
1. 複数の Windows ファイルサーバーをクラスタリング → 障害ドメインの分散
2. DFS-N（Distributed File System Namespace）で統一名前空間を提供
3. DFS-R（Distributed File System Replication）でサイト間レプリケーション

**Configuration Share のスケーリング**:
- 複数サーバーに DFS-R でレプリカ配置
- DFS-N でアクティブな読み取りターゲットとして複数サーバーを設定可能（読み取り専用のため安全）
- 管理者は 1 台のサーバーに対してのみ書き込み → DFS-R で各サイトに自動レプリケーション

**Profile Archive Share のスケーリング**:
- DFS-N で統一名前空間を設定
- **ただしアクティブターゲットは 1 つのみ**（読み書きデータのため、複数アクティブにするとデータ破損リスク）
- パッシブターゲットをフェイルオーバー用に設定

**垂直スケーリング**:
- ファイルサーバーの vCPU / メモリ / ディスク I/O 増強
- 高速ストレージ（SSD/NVMe）の使用

### ボトルネック分析

| 指標 | 確認方法 |
|---|---|
| ログイン / ログアウト時間 | FlexEngine ログで Profile Import/Export の所要時間を確認 |
| ファイルサーバー I/O | ディスクキュー長、IOPS を監視 |
| DFS-R レプリケーション遅延 | DFS Replication Health Report |
| Profile Archive サイズ膨張 | Helpdesk Support Tool で分析 |

---

## ベストプラクティス

1. **N+1 冗長設計**: すべてのコンポーネントで N+1 を確保し、障害時にもサービス継続
2. **定期的な容量レビュー**: 月次でリソース使用率のトレンド分析を実施
3. **ログインストーム対策**: ピーク時の同時接続数を基準にサイジング
4. **段階的スケーリング**: 小規模な変更を繰り返し、各段階で検証
5. **障害ドメインの分散**: 単一 vCenter / 単一ファイルサーバーへの過度な集約を避ける
6. **管理コンポーネントの分離**: 大規模環境では管理 VM（CS, AV Manager 等）を専用クラスタに配置

## アンチパターン

1. **上限値を超えたサイジング**: Configuration Maximums を超えるセッション数を単一 Pod に収容
2. **N+0 設計**: 冗長性なしで本番運用 → 単一障害で全ユーザーに影響
3. **トンネリング有効時の過大見積もり**: Secure Gateway 有効時の上限（2,000）を見落とす
4. **DEM Profile Archive の複数アクティブターゲット**: データ破損リスク
5. **モニタリング不在のスケーリング**: ボトルネック特定なしに闇雲にリソース追加

---

## 理解度チェックリスト

### Connection Server
- [ ] Connection Server の 1 台あたりのセッション上限（4,000 / 2,000）を説明できる
- [ ] Pod あたりの最大 CS 数（7）と最大セッション数（20,000）を把握している
- [ ] N+1 冗長を考慮したサイジング計算ができる
- [ ] Pod and Block アーキテクチャでのスケーリング戦略を説明できる
- [ ] ロードバランサーの Session Persistence 要件を理解している

### App Volumes
- [ ] App Volumes Manager のスケーリング手法（Multi-Manager + LB）を説明できる
- [ ] ストレージ容量の計算方法を理解している
- [ ] ログインストームが App Volumes に与える影響を説明できる
- [ ] Multi-Site 設計での Package レプリケーション方式を把握している

### DEM
- [ ] DEM のアーキテクチャが DB 不要であることを理解している
- [ ] Configuration Share と Profile Archive Share の違いを説明できる
- [ ] DFS-N / DFS-R を使用したスケーリング・レプリケーション方式を説明できる
- [ ] Profile Archive Share でアクティブターゲットを 1 つに限定する理由を説明できる
- [ ] ファイルサーバーのサイジング推奨値を把握している

### 全体
- [ ] Pod 内のクォーラム要件（(N/2)+1）を理解している（Horizon 2309 以降）
- [ ] CPA フェデレーション全体の上限値（50 Pods, 15 Sites, 350 CS, 250,000 Sessions）を把握している
